{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries and data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_csv('train_trimmed.csv',index_col=0)\n",
    "testing_df = pd.read_csv('test_trimmed.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.log(training_df['SalePrice']) # log price -- convention \n",
    "training_features = training_df.drop(['SalePrice'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1456, 78)\n",
      "TotalBsmtSF   SalePrice       0.646584\n",
      "SalePrice     TotalBsmtSF     0.646584\n",
      "              GarageCars      0.649256\n",
      "GarageCars    SalePrice       0.649256\n",
      "BsmtFullBath  BsmtFinSF1      0.661933\n",
      "BsmtFinSF1    BsmtFullBath    0.661933\n",
      "KitchenQual   SalePrice       0.666217\n",
      "SalePrice     KitchenQual     0.666217\n",
      "OverallQual   KitchenQual     0.667869\n",
      "KitchenQual   OverallQual     0.667869\n",
      "BedroomAbvGr  TotRmsAbvGrd    0.679346\n",
      "TotRmsAbvGrd  BedroomAbvGr    0.679346\n",
      "GrLivArea     2ndFlrSF        0.687430\n",
      "2ndFlrSF      GrLivArea       0.687430\n",
      "SalePrice     ExterQual       0.694628\n",
      "ExterQual     SalePrice       0.694628\n",
      "              KitchenQual     0.712513\n",
      "KitchenQual   ExterQual       0.712513\n",
      "GrLivArea     SalePrice       0.720516\n",
      "SalePrice     GrLivArea       0.720516\n",
      "BsmtFinType1  BsmtFinSF1      0.721871\n",
      "BsmtFinSF1    BsmtFinType1    0.721871\n",
      "OverallQual   ExterQual       0.721973\n",
      "ExterQual     OverallQual     0.721973\n",
      "YearBuilt     GarageYrBlt     0.776578\n",
      "GarageYrBlt   YearBuilt       0.776578\n",
      "BsmtFinSF2    BsmtFinType2    0.788940\n",
      "BsmtFinType2  BsmtFinSF2      0.788940\n",
      "1stFlrSF      TotalBsmtSF     0.800759\n",
      "TotalBsmtSF   1stFlrSF        0.800759\n",
      "SalePrice     OverallQual     0.800858\n",
      "OverallQual   SalePrice       0.800858\n",
      "TotRmsAbvGrd  GrLivArea       0.833979\n",
      "GrLivArea     TotRmsAbvGrd    0.833979\n",
      "Fireplaces    FireplaceQu     0.864979\n",
      "FireplaceQu   Fireplaces      0.864979\n",
      "GarageCars    GarageArea      0.886882\n",
      "GarageArea    GarageCars      0.886882\n",
      "PoolArea      PoolQC          0.930979\n",
      "PoolQC        PoolArea        0.930979\n",
      "GarageQual    GarageCond      0.959164\n",
      "GarageCond    GarageQual      0.959164\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# correlation Part\n",
    "# observe there is quite strong correlation between variables \n",
    "# so we apply PCA to handle this \n",
    "# However we will apply PCA after one-hot encoding\n",
    "correlation_matrix = training_df.corr().abs()\n",
    "s = correlation_matrix.unstack()\n",
    "so = s.sort_values(kind=\"quicksort\")\n",
    "so = so[:3192]\n",
    "print (training_df.shape)\n",
    "print (so[3150:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3249,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "so.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and validation\n",
    "valid_df = training_features.iloc[:100]\n",
    "training_df = training_features.iloc[100:]\n",
    "valid_label = label.iloc[:100]\n",
    "training_label = label.iloc[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MSZoning', 'Street', 'LandContour', 'LotConfig', 'Neighborhood', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Foundation', 'Heating', 'Electrical', 'GarageType', 'PavedDrive', 'MiscFeature', 'SaleType', 'SaleCondition']\n",
      "(1356, 213)\n",
      "(100, 213)\n",
      "(1459, 213)\n"
     ]
    }
   ],
   "source": [
    "# categorical variables --> one hot encoding\n",
    "\n",
    "# find out which columns is categorical\n",
    "cat_variables = []\n",
    "num_variables = []\n",
    "for name in training_df.columns:\n",
    "    # print (training_features[name].dtype.name)\n",
    "    if training_df[name].dtype.name == 'object':\n",
    "        cat_variables.append(name)\n",
    "    else:\n",
    "        num_variables.append(name)\n",
    "print (cat_variables)\n",
    "\n",
    "cat_dict = training_df[ cat_variables ].to_dict( orient = 'records' )\n",
    "cat_dict_valid = valid_df[ cat_variables ].to_dict( orient = 'records' )\n",
    "cat_dict_test = testing_df[cat_variables].to_dict(orient = 'records')\n",
    "\n",
    "training_numerical = training_df[ num_variables ].as_matrix()\n",
    "valid_numerical = valid_df[ num_variables].as_matrix()\n",
    "testing_numerical = testing_df[num_variables]\n",
    "#max_train = np.amax( training_numerical, 0 )\n",
    "\n",
    "#x_num_train = training_numerical / max_train\n",
    "#x_num_valid = valid_numerical/ max_train\n",
    "#x_num_test = testing_numerical / max_train\t\t# scale test by max_train\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "# vectorize\n",
    "\n",
    "vectorizer = DV( sparse = False )\n",
    "vec_x_cat_train = vectorizer.fit_transform( cat_dict )\n",
    "vec_x_cat_test = vectorizer.transform( cat_dict_test)\n",
    "vec_x_cat_valid = vectorizer.transform (cat_dict_valid)\n",
    "training_complete = np.hstack((training_numerical,vec_x_cat_train))\n",
    "valid_complete = np.hstack((valid_numerical,vec_x_cat_valid))\n",
    "testing_complete = np.hstack((testing_numerical,vec_x_cat_test))\n",
    "\n",
    "print (training_complete.shape)\n",
    "print (valid_complete.shape)\n",
    "print (testing_complete.shape)\n",
    "# # now we have one-hot encoding and normalized numerical variable \n",
    "# # next step we apply BernoulliRBM \n",
    "# from sklearn.neural_network import BernoulliRBM\n",
    "# RBM = BernoulliRBM(n_components=80)\n",
    "# training_complete_RBM_transform = RBM.fit_transform(training_complete)\n",
    "# testing_complete_RBM_transform = RBM.fit_transform(test_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1356, 178)\n",
      "(100, 178)\n",
      "(1459, 178)\n",
      "Explained variation per principal component (PCA): 0.9999999999518072\n"
     ]
    }
   ],
   "source": [
    "# Apply PCA here\n",
    "pca = PCA(n_components=178) \n",
    "training_complete_1 = pca.fit_transform(training_complete)\n",
    "valid_complete_1 = pca.transform(valid_complete)\n",
    "testing_complete_1 = pca.transform(testing_complete)\n",
    "print (training_complete_1.shape)\n",
    "print (valid_complete_1.shape)\n",
    "print (testing_complete_1.shape)\n",
    "print ('Explained variation per principal component (PCA): {}'.format(np.sum(pca.explained_variance_ratio_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0090608381743799\n",
      "0.015558549674764523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/scipy/linalg/basic.py:1226: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "error = []\n",
    "# Linear Regression -- used as benchmark\n",
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(training_complete_1, training_label)\n",
    "pred_labels = linear_regression.predict(testing_complete_1)\n",
    "pred_valid = linear_regression.predict(valid_complete_1)\n",
    "pred_train = linear_regression.predict(training_complete_1)\n",
    "print (mean_squared_error(pred_train, training_label))\n",
    "print (mean_squared_error(pred_valid, valid_label))\n",
    "error.append(mean_squared_error(pred_valid, valid_label))\n",
    "d = {'id': testing_numerical.index.values, 'SalePrice':np.exp(pred_labels) }\n",
    "submission = pd.DataFrame(data = d)\n",
    "submission.set_index(keys = 'id', inplace = True)\n",
    "submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01124998857170423\n",
      "0.017575346280409694\n"
     ]
    }
   ],
   "source": [
    "# still linear model - LASSO regression\n",
    "linear_regression_lasso = Lasso(alpha = 0.001, max_iter=50000)\n",
    "\n",
    "linear_regression_lasso.fit(training_complete_1, training_label)\n",
    "pred_labels_1 = linear_regression_lasso.predict(testing_complete_1)\n",
    "pred_valid_1 = linear_regression_lasso.predict(valid_complete_1)\n",
    "pred_train = linear_regression_lasso.predict(training_complete_1)\n",
    "print (mean_squared_error(pred_train, training_label))\n",
    "print (mean_squared_error(pred_valid_1, valid_label))\n",
    "error.append(mean_squared_error(pred_valid, valid_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009074532156673969\n",
      "0.015259256549053716\n"
     ]
    }
   ],
   "source": [
    "# still linear model - RIDGE regression\n",
    "linear_regression_ridge = Ridge(alpha = 0.39, max_iter=50000)\n",
    "linear_regression_ridge.fit(training_complete_1, training_label)\n",
    "pred_labels_2 = linear_regression_ridge.predict(testing_complete_1)\n",
    "pred_valid_2 = linear_regression_ridge.predict(valid_complete_1)\n",
    "pred_train = linear_regression_ridge.predict(training_complete_1)\n",
    "print (mean_squared_error(pred_train, training_label))\n",
    "print (mean_squared_error(pred_valid_2, valid_label))\n",
    "error.append(mean_squared_error(pred_valid, valid_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009923515812207379\n",
      "0.01583180033888915\n"
     ]
    }
   ],
   "source": [
    "# still linear model - ElasticNet regression\n",
    "linear_regression_ElasticNet = ElasticNet(alpha = 0.0006, max_iter=50000, l1_ratio = 0.53)\n",
    "\n",
    "linear_regression_ElasticNet.fit(training_complete_1, training_label)\n",
    "pred_labels_3 = linear_regression_ElasticNet.predict(testing_complete_1)\n",
    "pred_valid_3 = linear_regression_ElasticNet.predict(valid_complete_1)\n",
    "pred_train = linear_regression_ElasticNet.predict(training_complete_1)\n",
    "print (mean_squared_error(pred_train, training_label))\n",
    "print (mean_squared_error(pred_valid_3, valid_label))\n",
    "error.append(mean_squared_error(pred_valid, valid_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015159257703269043\n"
     ]
    }
   ],
   "source": [
    "# adding up three results\n",
    "results = (pred_labels_1 + pred_labels_2 + pred_labels_3)/3\n",
    "valid_results = (pred_valid_1 + pred_valid_2 + pred_valid_3)/3\n",
    "print (mean_squared_error(valid_results, valid_label))\n",
    "d = {'id': testing_numerical.index.values, 'SalePrice':np.exp(results) }\n",
    "submission = pd.DataFrame(data = d)\n",
    "submission.set_index(keys = 'id', inplace = True)\n",
    "submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0013861750265252019\n",
      "0.019954972002147117\n",
      "0.0013861750265252019\n",
      "0.020536626799532453\n",
      "0.0013861750265252019\n",
      "0.020365237586836442\n",
      "0.0013861750265252019\n",
      "0.02023325925327373\n",
      "0.0013861750265252019\n",
      "0.020649111651991216\n",
      "0.0013861750265252019\n",
      "0.020678320680378857\n",
      "0.0013861750265252019\n",
      "0.02058807460140826\n",
      "0.0013861750265252019\n",
      "0.020707597281343647\n",
      "0.0013861750265252019\n",
      "0.02076638728716542\n",
      "0.0013861750265252019\n",
      "0.020137360071141877\n",
      "0.0013861750265252019\n",
      "0.020595358663568257\n",
      "0.0013861750265252019\n",
      "0.02043057319672905\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting \n",
    "# Cross validation (n_estimators)\n",
    "\n",
    "n_est = [130, 140, 150]\n",
    "max_dep = [6, 7, 8, 9]\n",
    "\n",
    "er = 1111\n",
    "for n_e in n_est:\n",
    "    for m_d in max_dep:\n",
    "        regre = GradientBoostingRegressor(learning_rate=0.05,\n",
    "                                 max_depth=6, n_estimators = 100)\n",
    "        regre.fit(training_complete, training_label)\n",
    "        pred_labels = regre.predict(testing_complete)\n",
    "        pred_valid = regre.predict(valid_complete)\n",
    "        pred_train = regre.predict(training_complete)\n",
    "        print (mean_squared_error(pred_train, training_label))\n",
    "        print (mean_squared_error(pred_valid, valid_label))\n",
    "        if mean_squared_error(pred_valid, valid_label) < er: \n",
    "            best_n_e = n_e\n",
    "            best_m_d = m_d\n",
    "            result_XGB = pred_labels\n",
    "            results_valid = pred_valid\n",
    "            er = mean_squared_error(pred_valid, valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 6\n"
     ]
    }
   ],
   "source": [
    "print (best_n_e, best_m_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014614020529309909\n"
     ]
    }
   ],
   "source": [
    "valid_results_1 = (3* valid_results + results_valid)/4\n",
    "print (mean_squared_error(valid_results_1, valid_label))\n",
    "results_1 = (3 * results + result_XGB)/4\n",
    "d = {'id': testing_numerical.index.values, 'SalePrice':np.exp(results_1) }\n",
    "submission = pd.DataFrame(data = d)\n",
    "submission.set_index(keys = 'id', inplace = True)\n",
    "submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "n_est = [700, 800, 900, 1000, 1100, 1200, 1300]\n",
    "ee = 111\n",
    "for n_e in n_est:\n",
    "    random_forest = RandomForestRegressor(n_estimators=1000, verbose=1)\n",
    "    random_forest.fit(training_complete, training_label)\n",
    "    pred_labels = random_forest.predict(testing_complete)\n",
    "    pred_valid = random_forest.predict(valid_complete)\n",
    "    pred_train = random_forest.predict(training_complete)\n",
    "    print (mean_squared_error(pred_train, training_label))\n",
    "    print (mean_squared_error(pred_valid, valid_label))\n",
    "    if mean_squared_error(pred_valid, valid_label) < ee: \n",
    "            best_n_e_2 = n_e\n",
    "            best_m_d_2 = m_d\n",
    "            result_RF = pred_labels\n",
    "            results_valid_RF = pred_valid\n",
    "            ee = mean_squared_error(pred_valid, valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014871675175768189\n"
     ]
    }
   ],
   "source": [
    "# valid_results_2 = (4*valid_results_1+results_valid_RF)/5\n",
    "# print (mean_squared_error(valid_results_2, valid_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize the categorical variables left \n",
    "# create summarized variables \n",
    "# Tree models \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
